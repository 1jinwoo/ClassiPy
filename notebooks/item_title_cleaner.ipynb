{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "data_cleaner.py\n",
    "'''\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def read_search_strings(file_path='search_strings.csv'):\n",
    "    '''\n",
    "    Reads from csv from file_path\n",
    "    :return: pandas DataFrame of the csv\n",
    "    '''\n",
    "    df = pd.read_csv(file_path, header=0, sep=',', encoding='latin1')\n",
    "    return df\n",
    "\n",
    "\n",
    "def cleanup_categoryid(df):\n",
    "    '''\n",
    "    Assigns new category id starting from 1.\n",
    "    ** This function modifies df **\n",
    "    :return: dictionary[key] = categroyId\n",
    "    '''\n",
    "    i = -1\n",
    "    category_dict = dict()\n",
    "    for j, row in df.iterrows():\n",
    "        category = row[3]\n",
    "        if not category in category_dict.keys():\n",
    "            i += 1\n",
    "            category_dict[category] = i\n",
    "            df.at[j, 'categoryId'] = i\n",
    "        else:\n",
    "            df.at[j, 'categoryId'] = i\n",
    "    return df\n",
    "\n",
    "def clean_item_data(m):\n",
    "    #read in file using data_cleaner\n",
    "    df = read_search_strings()\n",
    "    \n",
    "    '''\n",
    "    removing . and all non-alphanumeric characters at the end of each word (e.g. 'oz.') \n",
    "    and preventing the removing of '7.5mm', except \", ', and space. \n",
    "    Ã† stays, might remove later\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        new_string = ''\n",
    "        if m == 1:\n",
    "            for item in row['item_title']:\n",
    "                item = ''.join(c for c in item if c.isalnum() or c == '\\\"' or c == '\\'' or c == ' ' or c == '.' or c == '$')\n",
    "                new_string += item\n",
    "            word_list = new_string.split()\n",
    "            new_word = ''\n",
    "            for w in word_list:\n",
    "                if w.endswith('.'):\n",
    "                    new_word += w[:-1] + ' '\n",
    "                else:\n",
    "                    new_word += w + ' '\n",
    "            new_string = new_word\n",
    "            df.at[index, 'item_title']= new_string\n",
    "        elif m == 0:\n",
    "            for item in row['item_title']:\n",
    "                item = ''.join(c.lower() for c in item if c.isalpha() or c == ' ')\n",
    "                new_string += item\n",
    "            word_list = new_string.split()\n",
    "            new_word = ''\n",
    "            for w in word_list:\n",
    "                new_word += w + ' '\n",
    "            new_string = new_word\n",
    "            df.at[index, 'item_title'] = new_string\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def data_split(df, train=0.65, valid=0.15, test=0.20):\n",
    "    \"\"\"\n",
    "    split data into training, validation, and test sets\n",
    "    :param df: the data set\n",
    "    :param train: percentage of training data\n",
    "    :param valid: percentage of validation data\n",
    "    :param test: percentage of test data\n",
    "    :return: X_train, X_valid, X_test, Y_train, Y_valid, Y_test\n",
    "    \"\"\"\n",
    "\n",
    "    # instantiate variables\n",
    "    column_headers = list(df.columns.values)\n",
    "    X_train = pd.DataFrame()\n",
    "    X_valid = pd.DataFrame()\n",
    "    X_test = pd.DataFrame()\n",
    "    Y_train = pd.DataFrame()\n",
    "    Y_valid = pd.DataFrame()\n",
    "    Y_test = pd.DataFrame()\n",
    "    \n",
    "    id_num = df['categoryId'].nunique()\n",
    "    for i in range(1, id_num+1):\n",
    "        x_category_df = df.loc[df['categoryId'] == i]['item_title']\n",
    "        y_category_df = df.loc[df['categoryId'] == i]['categoryId']\n",
    "\n",
    "        x_category_train_valid, x_category_test, y_category_train_valid, y_category_test = \\\n",
    "            train_test_split(x_category_df, y_category_df, test_size=test)\n",
    "        if valid != 0:\n",
    "            x_category_train, x_category_valid, y_category_train, y_category_valid = \\\n",
    "                train_test_split(x_category_train_valid, y_category_train_valid, train_size=train/(train+valid))\n",
    "            X_train = pd.concat([X_train, x_category_train], axis=0)\n",
    "            X_valid = pd.concat([X_valid, x_category_valid], axis=0)\n",
    "            X_test = pd.concat([X_test, x_category_test], axis=0)\n",
    "            Y_train = pd.concat([Y_train, y_category_train], axis=0)\n",
    "            Y_valid = pd.concat([Y_valid, y_category_valid], axis=0)\n",
    "            Y_test = pd.concat([Y_test, y_category_test], axis=0)\n",
    "        else:\n",
    "            X_train = pd.concat([X_train, x_category_train_valid], axis=0)\n",
    "            X_test = pd.concat([X_test, x_category_test], axis=0)\n",
    "            Y_train = pd.concat([Y_train, y_category_train_valid], axis=0)\n",
    "            Y_test = pd.concat([Y_test, y_category_test], axis=0)\n",
    "\n",
    "    return X_train, X_valid, X_test, Y_train, Y_valid, Y_test\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    df = clean_item_data(0)\n",
    "    for n in range(11120):\n",
    "        print(df.loc[n]['item_title'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
